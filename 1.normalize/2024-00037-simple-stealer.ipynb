{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1add555-2a7a-4ef4-9dfc-bbaff0b7c6fc",
   "metadata": {},
   "source": [
    "# Import helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9c51f1-71ea-451a-a61d-2fb1a937b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../0.shared_notebooks/0_helper_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee953f66-efe3-4b89-90ac-63a754947856",
   "metadata": {},
   "source": [
    "# Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20198a8-ef2a-4294-80a7-64ef7587103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CASE=\"DIVD-2024-00037\"\n",
    "SUB=\"set1\"\n",
    "IN_DIR=\"../IN\"\n",
    "OUT_DIR=\"../NORMALIZED\"\n",
    "ERR_DIR=\"../ERR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4905d716-62c5-4f83-ba4c-7ee9a4fded6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $IN_DIR\n",
    "!ls $ERR_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1019c2ec-7d91-4df6-9270-c3f8105b52b7",
   "metadata": {},
   "source": [
    "## Defaults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c137d-ebdc-436d-84b0-fc6845350161",
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults = [\n",
    "  None,  # ts_found (Timestamp when the data was \"found\")\n",
    "  None,  # ts_leaked (Timestamp when the data was stolen/leaked)\n",
    "  0,     # has_name (0/1 if the record has a name)\n",
    "  0,     # has_dob (0/1 if the record has a date of birth)\n",
    "  0,     # has_addr (0/1 if the record has a address)\n",
    "  0,     # has_phone (0/1 if the record has a )\n",
    "  0,     # has_cc (0/1 if the record has creditcard data)\n",
    "  0,     # has bankacc (0/1 if the record has a bank account)\n",
    "  0,     # has_ssn (0/1 if the record has a ssn)\n",
    "  0,     # has ip (0/1 if the record has an ip address)\n",
    "  0,     # extra_data (json object with extra data)\n",
    "]\n",
    "ts_from_file = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1ba4d4-2f97-4af8-966f-52c04cf48acf",
   "metadata": {},
   "source": [
    "## Read in files, guess column and type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9398ea-1824-4762-97a7-b02636d4048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=sorted(glob(f\"{IN_DIR}/*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b398e07-9291-41af-a499-6adc1c9eeea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4412c8-f0c6-4adc-a689-6e7c1272e765",
   "metadata": {},
   "outputs": [],
   "source": [
    "goodlines = 0\n",
    "badlines = 0\n",
    "for file in files:\n",
    "    filename=os.path.basename(file)\n",
    "    timestamp=os.path.getctime(file)    \n",
    "    lines = []\n",
    "    bad_lines = []\n",
    "    urlfield = [0,0,0]\n",
    "    types = [0,0]\n",
    "    error = \"\"\n",
    "    with open(file, 'rb') as fh:\n",
    "        for byteline in fh:\n",
    "            line = byteline.decode('utf-8', errors=\"replace\").strip()\n",
    "            ok = True\n",
    "            if re.search(r'^\\S+$', line) :\n",
    "                ok = True\n",
    "            else:\n",
    "                ok = False\n",
    "                error = \"BAD_PATTERN\"\n",
    "            \n",
    "            if \":\" in line:\n",
    "                fields = line.strip().split(\":\")\n",
    "            else: \n",
    "                ok = False\n",
    "                error = \"NO_COLON\"\n",
    "\n",
    "            # Quality check\n",
    "            if ok:\n",
    "                if re.match(r'^\\s',line) :\n",
    "                    ok = False\n",
    "                    error = \"HAS_SPACES\"\n",
    "                else:\n",
    "                    ok = True\n",
    "\n",
    "                if ok:\n",
    "                    # Fix split urls\n",
    "                    newfields = []\n",
    "                    for i, val in enumerate(fields):\n",
    "                        #if len(newfields) > 0 and newfields[-1] == \"http://111.90.130.4\": sleep()\n",
    "                        if (\n",
    "                            len(newfields) > 0 and \n",
    "                            (\n",
    "                                # http(s)://\n",
    "                                (\n",
    "                                    (\n",
    "                                        newfields[-1].endswith(\"https\") or \n",
    "                                        newfields[-1].endswith(\"http\") or \n",
    "                                        newfields[-1].endswith(\"android\")\n",
    "                                    )  and val.startswith(\"//\")   \n",
    "                                #) or (\n",
    "                                #   re.search(r'\\d$',newfields[-1]) and re.search(r'^\\d+[\\/$]',val)      \n",
    "                                ) or (\n",
    "                                    re.search(r'https?\\:\\/\\/[a-zA-Z0-9.\\-]+\\.([a-zA-z]{2,4}|\\d{1,3})$',newfields[-1]) and re.search(r'^\\d+[a-zA-Z0-9.\\-\\/]*',val)                                      )\n",
    "                            )\n",
    "                        ) :\n",
    "                            newfields[-1] = \"{}:{}\".format(newfields[-1],val)\n",
    "                        else:\n",
    "                            newfields.append(val)\n",
    "                    fields = newfields\n",
    "\n",
    "                if ok:\n",
    "                    if len(fields) < 2 or len(fields) > 3 :\n",
    "                        ok = False\n",
    "                        error = \"FIELD_COUNT\"\n",
    "                    else:\n",
    "                        ok = True\n",
    "\n",
    "                # Figure out type\n",
    "                if ok:\n",
    "                    if len(fields) > 2 and fields[0] and fields[1] and fields[2]:\n",
    "                        types[1] = types[1]+1\n",
    "                    else:\n",
    "                        types[0] = types[0]+1\n",
    "\n",
    "\n",
    "                # add fields to array\n",
    "                if ok:\n",
    "                    goodlines = goodlines+1\n",
    "                    while len(fields) < 3 :\n",
    "                        fields.append(\"\")\n",
    "                    fields.append(defaults[0])  # ts_found (Timestamp when the data was \"found\")\n",
    "                                                # ts_leaked (Timestamp when the data was stolen/leaked)\n",
    "                    if ts_from_file :\n",
    "                        fields.append(datetime.fromtimestamp(timestamp).strftime(\"%Y-%m-%d\"))\n",
    "                    else:\n",
    "                        fields.append(defaults[1])  \n",
    "                    fields.append(defaults[0])  # has_name (0/1 if the record has a name)\n",
    "                    fields.append(defaults[0])  # has_dob (0/1 if the record has a date of birth)\n",
    "                    fields.append(defaults[0])  # has_addr (0/1 if the record has a address)\n",
    "                    fields.append(defaults[0])  # has_phone (0/1 if the record has a )\n",
    "                    fields.append(defaults[0])  # has_cc (0/1 if the record has creditcard data)\n",
    "                    fields.append(defaults[0])  # has_bankacc (0/1 if the record has a bank account)\n",
    "                    fields.append(defaults[0])  # has_ssn (0/1 if the record has a ssn)\n",
    "                    fields.append(defaults[0])  # has_ip (0/1 if the record has an ip address)\n",
    "                                                # extra_data (json object with extra data)\n",
    "                    fields.append('{{ \"filename\" : \"{}\" }}'.format(filename))\n",
    "                    lines.append(fields)\n",
    "                else:\n",
    "                    bad_lines.append(f\"{error} - {line}\\n\")\n",
    "                    badlines = badlines+1\n",
    "                    \n",
    "                # Figure out field data type\n",
    "                if ok:\n",
    "                    if re.search(r'^(https?|android)\\:',fields[0]) : urlfield[0] = urlfield[0] + 1\n",
    "                    if re.search(r'^(https?|android)\\:',fields[2]) : urlfield[2] = urlfield[2] + 1\n",
    "    \n",
    "    if len(bad_lines) > 0 :\n",
    "        with open(f\"{ERR_DIR}/{filename}\", \"w\") as bfh:\n",
    "            bfh.writelines(bad_lines)\n",
    "    \n",
    "\n",
    "    # It is a stealer log if we have more then 25% urls\n",
    "    if (types[0]+types[1]) > 0 and types[1] / (types[0]+types[1]) > 0.25 :\n",
    "        ftype = \"s\"\n",
    "    else:\n",
    "        ftype = \"c\"\n",
    "\n",
    "    if ftype == \"s\":\n",
    "        if urlfield[2] > urlfield[0]:\n",
    "            column_names= [\"username\",\"passwd\",\"url\"]\n",
    "        else:\n",
    "            column_names= [\"url\",\"username\",\"passwd\"]\n",
    "    else:\n",
    "        column_names= [\"username\",\"passwd\",\"url\"]\n",
    "    for fn in [ \"ts_found\", \"ts_leaked\", \"has_name\", \"has_dob\", \"has_addr\", \"has_phone\", \"has_cc\", \"hasbankacc\", \"has_ssn\", \n",
    "                         \"has ip\", \"extra_data\" ] :\n",
    "        column_names.append(fn)\n",
    "    \n",
    "    df = pd.DataFrame(lines, columns=column_names)\n",
    "\n",
    "    if ftype == \"s\" :\n",
    "        df.to_csv(f\"{OUT_DIR}/{filename.replace(\".txt\",\".tsv\")}\",sep=\"\\t\", index=False, \n",
    "                  columns=[ \"username\",\"passwd\",\"url\", \"ts_found\", \"ts_leaked\", \"has_name\", \"has_dob\", \"has_addr\", \"has_phone\", \n",
    "                            \"has_cc\", \"hasbankacc\", \"has_ssn\", \"has ip\", \"extra_data\"]\n",
    "                 )\n",
    "    else : \n",
    "        # Not handling combos\n",
    "        pass\n",
    "        #df.to_csv(f\"{COMBO_DIR}/{filename.replace(\".txt\",\".tsv\")}\",sep=\"\\t\", index=False, columns=[\"user\",\"pass\",\"telegram_date\",\"file\"])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7266e876-5865-4185-a724-39e085783623",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"{:,} ({:.1f})% good - {:,} bad ({:.1f})%  - {:,} total\".format(goodlines, (goodlines/(goodlines+badlines)*100), badlines, (badlines/(goodlines+badlines)*100), (goodlines+badlines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cf9be3-03dd-44cc-9d62-0879b3429fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $OUT_DIR\n",
    "!ls -l $ERR_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4172d79-2c73-4813-9876-30398354e405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
